{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified from source: https://github.com/mprat/pascal-voc-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import voc_utils\n",
    "from more_itertools import unique_everseen\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize, imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'C:/Users/xx/Downloads/PASCAL/VOCtrainval_11-May-2012/VOCdevkit/VOC2012/'\n",
    "img_dir = os.path.join(root_dir, 'JPEGImages/')\n",
    "ann_dir = os.path.join(root_dir, 'Annotations/')\n",
    "set_dir = os.path.join(root_dir, 'ImageSets', 'Main/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'trainval', 'tvmonitor', 'val']\n"
     ]
    }
   ],
   "source": [
    "# list image sets\n",
    "all_files = os.listdir(set_dir)\n",
    "#all_files = !ls {set_dir}\n",
    "image_sets = sorted(list(set([filename.replace('.txt', '').strip().split('_')[0] for filename in all_files])))\n",
    "print(image_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_sets)-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category name is from above, dataset is either \"train\" or\n",
    "# \"val\" or \"train_val\"\n",
    "def imgs_from_category(cat_name, dataset):\n",
    "    filename = os.path.join(set_dir, cat_name + \"_\" + dataset + \".txt\")\n",
    "    df = pd.read_csv(\n",
    "        filename,\n",
    "        delim_whitespace=True,\n",
    "        header=None,\n",
    "        names=['filename', 'true'])\n",
    "    return df\n",
    "\n",
    "def imgs_from_category_as_list(cat_name, dataset):\n",
    "    df = imgs_from_category(cat_name, dataset)\n",
    "    df = df[df['true'] == 1]\n",
    "    return df['filename'].values\n",
    "\n",
    "def annotation_file_from_img(img_name):\n",
    "    return os.path.join(ann_dir, img_name) + '.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation operations\n",
    "def load_annotation(img_filename):\n",
    "    xml = \"\"\n",
    "    with open(annotation_file_from_img(img_filename)) as f:\n",
    "        xml = f.readlines()\n",
    "    xml = ''.join([line.strip('\\t') for line in xml])\n",
    "    return BeautifulSoup(xml,\"html.parser\")#return BeautifulSoup(xml)\n",
    "\n",
    "def get_all_obj_and_box(objname, img_set):\n",
    "    img_list = imgs_from_category_as_list(objname, img_set)\n",
    "    \n",
    "    for img in img_list:\n",
    "        annotation = load_annotation(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# image operations\n",
    "def load_img(img_filename):\n",
    "    return Image.open(os.path.join(img_dir, img_filename))\n",
    "    #return Image.open(os.path.join(img_dir, img_filename + '.jpg'))\n",
    "    #return io.load_image(os.path.join(img_dir, img_filename + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(category, dataset):\n",
    "    '''\n",
    "    Args:\n",
    "    category (str): name of category to load\n",
    "    dataset  (str): 'train' or 'val' set\n",
    "    \n",
    "    Returns: dataframe with xxxx data\n",
    "    '''\n",
    "    to_find = category\n",
    "    \n",
    "    filePath = '{}csvs/'.format(root_dir)\n",
    "    if not os.path.exists(filePath):\n",
    "        os.makedirs(filePath)     \n",
    "    filename = '{}{}_{}.csv'.format(filePath,dataset,category)\n",
    "      \n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        img_list = imgs_from_category_as_list(to_find, dataset)\n",
    "        data = []\n",
    "        for item in img_list:\n",
    "            anno = load_annotation(item)\n",
    "            objs = anno.findAll('object')\n",
    "            \n",
    "            fname = anno.findChild('filename').contents[0]\n",
    "            \n",
    "            hasCat = 0\n",
    "            hasDog = 0\n",
    "            hasHorse=0\n",
    "            hasPerson = 0\n",
    "            \n",
    "            for obj in objs:\n",
    "                obj_names = obj.findChildren('name')\n",
    "                if obj_names[0].contents[0] == 'cat':\n",
    "                    hasCat = 1\n",
    "                elif obj_names[0].contents[0] == 'dog':\n",
    "                    hasDog = 1\n",
    "                elif obj_names[0].contents[0] == 'horse':\n",
    "                    hasHorse = 1\n",
    "                elif obj_names[0].contents[0] == 'person':\n",
    "                    hasPerson = 1\n",
    "            \n",
    "            data.append([fname, hasCat, hasDog, hasHorse, hasPerson])\n",
    "        df = pd.DataFrame(data, columns=['fname', 'cat', 'dog', 'horse', 'person'])\n",
    "        df.to_csv(filename, index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train-Val-Test data (save npy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07/04/2018: Split (x,y) data and then save them in npy array\n",
    "#=======================================\n",
    "\n",
    "#train-val-test = 85-10-5\n",
    "val_to_trainSplit = 0.10/0.85\n",
    "testSplit = 0.05\n",
    "\n",
    "# Intended size = 128, leave a bit of buffer for rounding\n",
    "imgSize = 128.\n",
    "data_dir = '{}data/'.format(root_dir)\n",
    "\n",
    "categories = ['cat', 'dog', 'horse', 'person']\n",
    "dataset = 'trainval'\n",
    "\n",
    "trainFiles= []\n",
    "valFiles  = []\n",
    "testFiles = []\n",
    "yTrain    = []\n",
    "yVal      = []\n",
    "yTest     = []\n",
    "xTrain    = []\n",
    "xVal      = []\n",
    "xTest     = []\n",
    "\n",
    "\n",
    "for categ in categories:\n",
    "    df = load_data(categ, dataset)\n",
    "\n",
    "    # >3 classes in img\n",
    "    indices = np.where(df.sum(axis=1)>=3)[0]\n",
    "    nTest = int(np.ceil(testSplit*len(indices)))\n",
    "    nLeft = int(len(indices) - nTest)\n",
    "    nVal  = int(np.ceil(val_to_trainSplit*nLeft))\n",
    "    nTrain= int(nLeft - nVal)\n",
    "\n",
    "    if nTest !=0:\n",
    "        testFiles += df.iloc[indices[:nTest]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[:nTest]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yTest += list(currY)\n",
    "    if nVal  !=0:\n",
    "        valFiles  += df.iloc[indices[nTest:(nTest+nVal)]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[nTest:(nTest+nVal)]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yVal += list(currY)   \n",
    "    if nTrain!=0:\n",
    "        trainFiles+= df.iloc[indices[-nTrain:]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[-nTrain:]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yTrain+=list(currY)\n",
    "\n",
    "    # Only 2 classes in img\n",
    "    indices = np.where(df.sum(axis=1)==2)[0]\n",
    "    nTest = int(np.ceil(testSplit*len(indices)))\n",
    "    nLeft = int(len(indices) - nTest)\n",
    "    nVal  = int(np.ceil(val_to_trainSplit*nLeft))\n",
    "    nTrain= int(nLeft - nVal)\n",
    "\n",
    "    if nTest !=0:\n",
    "        testFiles += df.iloc[indices[:nTest]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[:nTest]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yTest += list(currY)\n",
    "    if nVal  !=0:\n",
    "        valFiles  += df.iloc[indices[nTest:(nTest+nVal)]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[nTest:(nTest+nVal)]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yVal += list(currY)   \n",
    "    if nTrain!=0:\n",
    "        trainFiles+= df.iloc[indices[-nTrain:]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[-nTrain:]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yTrain+=list(currY)\n",
    "\n",
    "    # Only 1 class in img\n",
    "    indices = np.where(df.sum(axis=1)==1)[0]\n",
    "    nTest = int(np.ceil(testSplit*len(indices)))\n",
    "    nLeft = int(len(indices) - nTest)\n",
    "    nVal  = int(np.ceil(val_to_trainSplit*nLeft))\n",
    "    nTrain= int(nLeft - nVal)\n",
    "\n",
    "    if nTest !=0:\n",
    "        testFiles += df.iloc[indices[:nTest]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[:nTest]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yTest += list(currY)\n",
    "    if nVal  !=0:\n",
    "        valFiles  += df.iloc[indices[nTest:(nTest+nVal)]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[nTest:(nTest+nVal)]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yVal += list(currY)   \n",
    "    if nTrain!=0:\n",
    "        trainFiles+= df.iloc[indices[-nTrain:]]['fname'].tolist()\n",
    "        currY = df.iloc[indices[-nTrain:]].drop(labels='fname',axis=1).as_matrix()\n",
    "        yTrain+=list(currY)\n",
    "\n",
    "                \n",
    "\n",
    "total = len(testFiles) + len(valFiles) + len(trainFiles)\n",
    "print(':: total={}; test={}, val={}, train={}'.format(total,len(testFiles),len(valFiles),len(trainFiles)))\n",
    "\n",
    "# Process img to npy\n",
    "for xFiles, x in zip([testFiles, valFiles, trainFiles], [xTest, xVal, xTrain]):\n",
    "    for imgName in xFiles:\n",
    "        img_np = np.array(imread(img_dir+imgName),dtype=np.float32)\n",
    "        #print('original:{}'.format(img_np.size))\n",
    "        \n",
    "        x.append( imresize(img_np,(int(imgSize),int(imgSize)), interp='bilinear') )\n",
    "        #print(img_np.size)\n",
    "\n",
    "\n",
    "#convert from list of arrays back to np.array\n",
    "yTest  = np.array(yTest, dtype=np.float32)\n",
    "yVal   = np.array(yVal, dtype=np.float32)\n",
    "yTrain = np.array(yTrain, dtype=np.float32)\n",
    "\n",
    "xTest  = np.array(xTest, dtype=np.float32) /255.\n",
    "xVal   = np.array(xVal, dtype=np.float32)  /255.\n",
    "xTrain = np.array(xTrain, dtype=np.float32)/255.\n",
    "\n",
    "np.save('{}xTrain.npy'.format(data_dir), xTrain)\n",
    "np.save('{}xVal.npy'.format(data_dir), xVal)\n",
    "np.save('{}xTest.npy'.format(data_dir), xTest)\n",
    "np.save('{}yTrain.npy'.format(data_dir), yTrain)\n",
    "np.save('{}yVal.npy'.format(data_dir), yVal)\n",
    "np.save('{}yTest.npy'.format(data_dir), yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save associated filenames\n",
    "import pickle\n",
    "\n",
    "with open(\"../CS6208/data/xTestFileNames.txt\", \"wb\") as fp:\n",
    "  pickle.dump(testFiles, fp)\n",
    "with open(\"../CS6208/data/xValFileNames.txt\", \"wb\") as fp:\n",
    "  pickle.dump(valFiles, fp)\n",
    "with open(\"../CS6208/data/xTrainFileNames.txt\", \"wb\") as fp:\n",
    "  pickle.dump(trainFiles, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess images to 128x128 and save into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07/04/2018: Split data and then place into folders\n",
    "#=======================================\n",
    "# ASSUMES FOLDERS ARE ALREADY CREATED\n",
    "# ./data/{train, val, test}/{cat,dog,horse,person}\n",
    "\n",
    "#train-val-test = 85-10-5\n",
    "val_to_trainSplit = 0.10/0.85\n",
    "testSplit = 0.05\n",
    "\n",
    "imgSize = 128.\n",
    "train_dir = '{}data/train/'.format(root_dir)\n",
    "val_dir = '{}data/val/'.format(root_dir)\n",
    "test_dir = '{}data/test/'.format(root_dir)\n",
    "\n",
    "categories = ['cat', 'dog', 'horse', 'person']\n",
    "dataset = 'trainval'\n",
    "\n",
    "for categ in categories:\n",
    "    df = load_data(categ, dataset)\n",
    "    \n",
    "    trainFiles =[]\n",
    "    valFiles   =[]\n",
    "    testFiles  =[]\n",
    "\n",
    "    # >3 classes in img\n",
    "    indices = np.where(df.sum(axis=1)>=3)[0]\n",
    "    nTest = int(np.ceil(testSplit*len(indices)))\n",
    "    nLeft = int(len(indices) - nTest)\n",
    "    nVal  = int(np.ceil(val_to_trainSplit*nLeft))\n",
    "    nTrain= int(nLeft - nVal)\n",
    "\n",
    "    if nTest !=0:testFiles += df.iloc[indices[:nTest]]['fname'].tolist()\n",
    "    if nVal  !=0:valFiles  += df.iloc[indices[nTest:(nTest+nVal)]]['fname'].tolist()\n",
    "    if nTrain!=0:trainFiles+= df.iloc[indices[-nTrain:]]['fname'].tolist()\n",
    "\n",
    "    # Only 2 classes in img\n",
    "    indices = np.where(df.sum(axis=1)==2)[0]\n",
    "    nTest = int(np.ceil(testSplit*len(indices)))\n",
    "    nLeft = int(len(indices) - nTest)\n",
    "    nVal  = int(np.ceil(val_to_trainSplit*nLeft))\n",
    "    nTrain= int(nLeft - nVal)\n",
    "\n",
    "    if nTest !=0:testFiles += df.iloc[indices[:nTest]]['fname'].tolist()\n",
    "    if nVal  !=0:valFiles  += df.iloc[indices[nTest:(nTest+nVal)]]['fname'].tolist()\n",
    "    if nTrain!=0:trainFiles+= df.iloc[indices[-nTrain:]]['fname'].tolist()\n",
    "\n",
    "    # Only 1 class in img\n",
    "    indices = np.where(df.sum(axis=1)==1)[0]\n",
    "    nTest = int(np.ceil(testSplit*len(indices)))\n",
    "    nLeft = int(len(indices) - nTest)\n",
    "    nVal  = int(np.ceil(val_to_trainSplit*nLeft))\n",
    "    nTrain= int(nLeft - nVal)\n",
    "\n",
    "    if nTest !=0:testFiles += df.iloc[indices[:nTest]]['fname'].tolist()\n",
    "    if nVal  !=0:valFiles  += df.iloc[indices[nTest:(nTest+nVal)]]['fname'].tolist()\n",
    "    if nTrain!=0:trainFiles+= df.iloc[indices[-nTrain:]]['fname'].tolist()\n",
    "    \n",
    "    total = len(testFiles) + len(valFiles) + len(trainFiles)\n",
    "    print('{}:: total={}; test={}, val={}, train={}'.format(categ, total,len(testFiles),len(valFiles),len(trainFiles)))\n",
    "    \n",
    "    #################################################\n",
    "    # Save images into folders per categ, per dataset\n",
    "    #################################################\n",
    "    for xFiles,dirName in zip([testFiles, valFiles, trainFiles], [test_dir, val_dir, train_dir]):\n",
    "        for imgName in xFiles:\n",
    "            img_np = imread(img_dir+imgName)\n",
    "            #print('original:{}'.format(img_np.size))\n",
    "            img_np = imresize(img_np,(int(imgSize),int(imgSize)), interp='bilinear')\n",
    "            imsave('{}{}/{}'.format(dirName, categ, imgName), img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that %split is correct\n",
    "total = len(testFiles) + len(valFiles) + len(trainFiles)\n",
    "print(float(len(trainFiles))/total)\n",
    "print('total (incl. overlap)={};\\ntest={},val={},train={}'.format(total,len(testFiles),len(valFiles),len(trainFiles)))\n",
    "del total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['cat', 'dog', 'horse', 'person']\n",
    "datasets = ['trainval']#,'train','val']\n",
    "\n",
    "summary = []\n",
    "for dataset in datasets:\n",
    "    for categ in categories:\n",
    "        df = load_data(categ,dataset)\n",
    "\n",
    "        clsMore3 = (df.sum(axis=1) >= 3).sum()\n",
    "        cls2 = (df.sum(axis=1) == 2).sum()\n",
    "        cls1 = (df.sum(axis=1) == 1).sum()\n",
    "        \n",
    "        summary.append([clsMore3,cls2,cls1])\n",
    "df_summary = pd.DataFrame(summary, columns=['clsMore3', 'cls2', 'cls1'])\n",
    "df_summary['categ'] = categories\n",
    "df_summary    \n",
    "    #print('{}: >3({}), 2({}), 1({})'.format(categ, clsMore3,cls2,cls1))\n",
    "\n",
    "#(df[['cat', 'person']].sum(axis=1) == 2).sum()\n",
    "np.where(df.sum(axis=1) >= 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:extractImgs_py3]",
   "language": "python",
   "name": "conda-env-extractImgs_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
