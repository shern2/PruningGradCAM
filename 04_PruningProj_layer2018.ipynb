{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2385
    },
    "colab_type": "code",
    "id": "rp9GMyU4Chrx",
    "outputId": "c6dbb9f0-982d-4de7-f089-189a87b6e5e1"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3225,
     "status": "error",
     "timestamp": 1524039387020,
     "user": {
      "displayName": "Weicong Sng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109857048975915125172"
     },
     "user_tz": -480
    },
    "id": "6KjZBNyVClow",
    "outputId": "a2b1c890-d2d9-40a9-df16-996d194ed4e5"
   },
   "outputs": [],
   "source": [
    "#!google-drive-ocamlfuse -cc\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "import os\n",
    "os.chdir(\"/content/drive/GPU/CS6208/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H4WIE9EeCusa"
   },
   "outputs": [],
   "source": [
    "!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7911,
     "status": "ok",
     "timestamp": 1524037407742,
     "user": {
      "displayName": "Weicong Sng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109857048975915125172"
     },
     "user_tz": -480
    },
    "id": "hoUZrBWTEj6z",
    "outputId": "1a05d118-f19d-47da-df36-793300757219"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eh9DRBByKuvV"
   },
   "source": [
    "## (All retained) Base Model and Basic params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IONCe3dJKuvX"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "batchSize = 64\n",
    "trainSteps = 5798//batchSize +1\n",
    "valSteps   =  783//batchSize +1\n",
    "testSteps  =  354//batchSize +1\n",
    "imgSize = 128\n",
    "\n",
    "\n",
    "def ourModel(inputShape):\n",
    "  \n",
    "  num_classes = 4\n",
    "\n",
    "  base_model = VGG16(include_top=False,input_shape=inputShape)\n",
    "  x = base_model.output\n",
    "\n",
    "  x = GlobalAveragePooling2D(name='glob_pool')(x)\n",
    "  x = Dense(256, activation='relu', name='dense_1')(x)\n",
    "  predictions = Dense(num_classes, activation='softmax', name='dense_F')(x)\n",
    "\n",
    "  model = Model(inputs=base_model.input, outputs=predictions)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GM656Vm4Kuvb"
   },
   "outputs": [],
   "source": [
    "# Note that xTrain and xVal are normalized by /=255\n",
    "xTrain = np.load('./data/xTrain.npy', mmap_mode='r')\n",
    "yTrain = np.load('./data/yTrain.npy', mmap_mode='r')\n",
    "xVal   = np.load('./data/xVal.npy', mmap_mode='r')\n",
    "yVal   = np.load('./data/yVal.npy', mmap_mode='r')\n",
    "\n",
    "categories = ['cat','dog','horse','person']\n",
    "datasets = ['train','val','test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "McHlKnftqm81"
   },
   "source": [
    "### Keras Surgeon (Layer Pruning)\n",
    "(Source:https://github.com/BenWhetton/keras-surgeon; visited: 03/08/2018)\n",
    "\n",
    "Iteratively prune conv layers from deepest to shallowest. Prune blockX_conv3 and blockX_conv2, but leave the blockX_conv1 blocks. \n",
    "\n",
    "This is to ensure that the input shape to the subsequent block remains the same and thus  Keras Surgeon can work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RvEvzDExqm87"
   },
   "outputs": [],
   "source": [
    "# Removed 'dense_1' and blockX_conv1 blocks since Keras Surgeon cannot handle them\n",
    "layerNames = ['block5_conv3','block5_conv2',\n",
    "              'block4_conv3','block4_conv2',\n",
    "              'block3_conv3','block3_conv2',\n",
    "              'block2_conv2',\n",
    "              'block1_conv2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ha8oqvehcIf9",
    "outputId": "acf9dc08-ad20-447f-d025-e7eb47a78f8e"
   },
   "outputs": [],
   "source": [
    "from kerassurgeon import identify\n",
    "from kerassurgeon.operations import delete_channels, delete_layer\n",
    "#from kerassurgeon import Surgeon\n",
    "#surgeonDelConvPool = Surgeon(model)\n",
    "#surgeonDelConvPool.add_job('delete_layer', model, 'block4_pool')\n",
    "#surgeonDelConvPool.add_job('delete_layer', model, 'block4_conv1')\n",
    "#model = surgeonDelConvPool.operate()\n",
    "\n",
    "#Initializations\n",
    "#===============\n",
    "# Initialize from last tuned layer\n",
    "filepathLastTuned  = './baseModel/modelBasev3.004-0.73.hdf5'\n",
    "model = load_model(filepathLastTuned, compile=False)\n",
    "filepathTuned  = filepathLastTuned\n",
    "    \n",
    "#opt = Adam(lr=0.1, decay=1e-6)\n",
    "opt = SGD(lr=0.001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "scores = model.evaluate(xVal, yVal, verbose=0)\n",
    "print('Val loss:', scores[0])\n",
    "print('Val accuracy:', scores[1])\n",
    "baseAccuracy = scores[1]\n",
    "\n",
    "accThresh  = 0.03 # Pruning threshold (accuracy)\n",
    "chThresh   = 20    # Pruning threshold (channel)\n",
    "predAccuracy = baseAccuracy\n",
    "bestAccuracy = baseAccuracy\n",
    "batch_size = 64\n",
    "num_classes = 4\n",
    "epochs = 200\n",
    "\n",
    "earlyStop = EarlyStopping(monitor='val_loss', patience=2,verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                        factor=0.5,\n",
    "                                        patience=0,\n",
    "                                        verbose=1,\n",
    "                                        epsilon=0.0001,\n",
    "                                        cooldown=0,\n",
    "                                        min_lr=0)\n",
    "\n",
    "datagenTrain = ImageDataGenerator()\n",
    "datagenTrain.fit(xTrain)\n",
    "trainGen = datagenTrain.flow(xTrain,yTrain, batch_size=batchSize)\n",
    "\n",
    "datagenVal = ImageDataGenerator()\n",
    "datagenVal.fit(xVal)\n",
    "valGen = datagenVal.flow(xVal,yVal, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1516
    },
    "colab_type": "code",
    "id": "TBPw1shkUb12",
    "outputId": "a4bab08b-9b7d-4921-fc87-66cbef872c53"
   },
   "outputs": [],
   "source": [
    "for layerName in layerNames:\n",
    "  print('==========')\n",
    "  print('Pruning layer: {}'.format(layerName))\n",
    "\n",
    "  dest_path = './models/m2p02_{}/'.format(layerName)\n",
    "  if not os.path.exists(dest_path):\n",
    "    os.makedirs(dest_path)\n",
    "\n",
    "  # reload the optimizer so that each layer starts with this lr\n",
    "  opt = SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "  # Prune layers\n",
    "  layer = model.get_layer(name=layerName)\n",
    "  model = delete_layer(model, layer, copy=False)\n",
    "\n",
    "  model.compile(optimizer=opt,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  #Manual rubbish collection\n",
    "  gc.collect()\n",
    "\n",
    "  scores = model.evaluate(xVal, yVal,batch_size=batchSize,verbose=0)\n",
    "  print('model after pruning: [loss,acc] = [{:.3f},{:.3f}]\\n'.format(scores[0],scores[1]))\n",
    "\n",
    "  # Save pruned model before tuning\n",
    "  filepathPruned=\"{}modelPruned.{}.hdf5\".format(dest_path,layerName)\n",
    "  model.save(filepathPruned,include_optimizer=False)\n",
    "\n",
    "  # Save predictions (pre-tune)\n",
    "  pred = model.predict(xVal, batch_size=batchSize)\n",
    "  filepathPruned_pred = \"{}modelPruned.{}_pred.npy\".format(dest_path,layerName)\n",
    "  np.save(filepathPruned_pred, pred)\n",
    "\n",
    "\n",
    "  model.fit_generator(trainGen, steps_per_epoch=trainSteps,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=valGen, validation_steps=valSteps,\n",
    "                  callbacks=[earlyStop, reduce_lr],\n",
    "                  verbose = 1,\n",
    "                  workers=1)\n",
    "\n",
    "  scores = model.evaluate(xVal, yVal,batch_size=batchSize,verbose=0)\n",
    "  print('model after retraining: [loss,acc] = [{:.3f},{:.3f}]\\n'.format(scores[0],scores[1]))\n",
    "\n",
    "\n",
    "  # Save tuned model after earlyStop\n",
    "  filepathTuned      = \"{}modelTuned.{}.hdf5\".format(dest_path,layerName)\n",
    "  model.save(filepathTuned,include_optimizer=False)\n",
    "\n",
    "  # Save predictions (tuned)\n",
    "  pred = model.predict(xVal, batch_size=batchSize)\n",
    "  filepathTuned_pred = \"{}modelTuned.{}_pred.npy\".format(dest_path,layerName)\n",
    "  np.save(filepathTuned_pred, pred)\n",
    "\n",
    "  # Exit while-loop if predAccuracy performs worse than some threshold\n",
    "  _, predAccuracy = model.evaluate(xVal, yVal,batch_size=batchSize,verbose=0)\n",
    "  if predAccuracy > bestAccuracy:\n",
    "    bestAccuracy = predAccuracy\n",
    "  elif (bestAccuracy-predAccuracy) > accThresh:\n",
    "    print('Accuracy fell too much: {:.3f} > accThresh {:.3f}'.format((bestAccuracy-predAccuracy), accThresh))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "PruningProj_Layer2018.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
