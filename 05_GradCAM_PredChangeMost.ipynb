{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9272,
     "status": "ok",
     "timestamp": 1524002422978,
     "user": {
      "displayName": "Shern Yap",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100597149862734635322"
     },
     "user_tz": -480
    },
    "id": "hoUZrBWTEj6z",
    "outputId": "bc36a870-2494-4747-a308-742d2ad2be81",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseModelPath  = './baseModel/modelBasev3.004-0.73.hdf5'\n",
    "baseModel = load_model(baseModelPath, compile=False)\n",
    "\n",
    "modelPath = './models/m2p01_block2_conv1/modelTuned.block2_conv1.001-022.hdf5'\n",
    "model = load_model(modelPath, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that xTrain and xVal are normalized by /=255\n",
    "#xTrain = np.load('./data/xTrain.npy', mmap_mode='r')\n",
    "#yTrain = np.load('./data/yTrain.npy', mmap_mode='r')\n",
    "xVal   = np.load('./data/xVal.npy', mmap_mode='r')\n",
    "yVal   = np.load('./data/yVal.npy', mmap_mode='r')\n",
    "\n",
    "import pickle\n",
    "with open(\"./data/xValFileNames.txt\", \"rb\") as fp:\n",
    "  xValFileNames = pickle.load(fp)\n",
    "xValFileNames = np.array(xValFileNames)\n",
    "categories = ['cat','dog','horse','person']\n",
    "datasets = ['train','val','test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predBase = np.load('./baseModel/modelBasev3.004-0.73_pred.npy')\n",
    "pred = np.load('./models/m2p01_block2_conv1/modelTuned.block2_conv1.001-022_pred.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get indices of top N imgs that changed prediction for each class\n",
    "# L1 DISTANCE\n",
    "N=3\n",
    "\n",
    "topNIdx = np.zeros((0,4), dtype=np.int)\n",
    "predChange = np.abs(pred - predBase)\n",
    "pred_tmp = predChange\n",
    "\n",
    "for n in range(N):\n",
    "    idx = np.argmax(pred_tmp,axis=0)\n",
    "    topNIdx = np.append(arr=topNIdx,axis=0,values=idx.reshape((1,4)))\n",
    "    pred_tmp = np.delete(pred_tmp, idx,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topN = xValFileNames[topNIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM the top changed imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-p23gNSnCF8B",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from imageio import imread, mimsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "36r1iwiICF8I",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgSize=128\n",
    "H = imgSize\n",
    "W = imgSize\n",
    "\n",
    "N_CLASS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYrAIRdnCF8K"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vSQSOcFEQ6t0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(modelPath):\n",
    "  \"\"\"Function returning keras model instance.\n",
    "  \"\"\"\n",
    "  model = load_model(modelPath, compile=False)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_W6hjArKCF8L",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_image(path, preprocess=True):\n",
    "  \"\"\"Load and preprocess image.\"\"\"\n",
    "  if preprocess:\n",
    "    x = np.array(imread(path),dtype=np.float32)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "    x/=255. # This was the only preprocessing I did... rather than keras.applications.preprocess_input(x)\n",
    "  else:\n",
    "    x = image.load_img(path, target_size=(H, W))\n",
    "  return x\n",
    "\n",
    "def deprocess_image(x):\n",
    "  \"\"\"Same normalization as in:\n",
    "  https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "  \"\"\"\n",
    "  x = x.copy()\n",
    "  if np.ndim(x) > 3:\n",
    "    x = np.squeeze(x)\n",
    "  # normalize tensor: center on 0., ensure std is 0.1\n",
    "  x -= x.mean()\n",
    "  x /= (x.std() + 1e-5)\n",
    "  x *= 0.1\n",
    "\n",
    "  # clip to [0, 1]\n",
    "  x += 0.5\n",
    "  x = np.clip(x, 0, 1)\n",
    "\n",
    "  # convert to RGB array\n",
    "  x *= 255\n",
    "  if K.image_dim_ordering() == 'th':\n",
    "    x = x.transpose((1, 2, 0))\n",
    "  x = np.clip(x, 0, 255).astype('uint8')\n",
    "  return x\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "  \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "  return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NohZZJ4yIESE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "\n",
    "CLASS_INDEX = json.load(open('./myModel_class_index.json'))\n",
    "    \n",
    "def decode_predictions(preds, top=4):\n",
    "    \"\"\"Decodes the prediction of ourModel.\n",
    "    # Arguments\n",
    "        preds: Numpy tensor encoding a batch of predictions.\n",
    "        top: Integer, how many top-guesses to return.\n",
    "    # Returns\n",
    "        A list of lists of top class prediction tuples\n",
    "        `(class_name, class_description, score)`.\n",
    "        One list of tuples per sample in batch input.\n",
    "    # Raises\n",
    "        ValueError: In case of invalid shape of the `pred` array\n",
    "            (must be 2D).\n",
    "    # Note: this is a modification of keras.applications.imagenet_utils.preprocess_input\n",
    "    \"\"\"\n",
    "    global CLASS_INDEX\n",
    "    if len(preds.shape) != 2 or preds.shape[1] != 4:\n",
    "        raise ValueError('`decode_predictions` expects '\n",
    "                         'a batch of predictions '\n",
    "                         '(i.e. a 2D array of shape (samples, 4)). '\n",
    "                         'Found array with shape: ' + str(preds.shape))\n",
    "    \n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
    "        result.sort(key=lambda x: x[2], reverse=True)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WCMGommvCF8O",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_guided_model(modelPath):\n",
    "    \"\"\"Function returning modified model.\n",
    "    \n",
    "    Changes gradient function for all ReLu activations\n",
    "    according to Guided Backpropagation.\n",
    "    \"\"\"\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) * \\\n",
    "                   tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': 'GuidedBackProp'}):\n",
    "        new_model = build_model(modelPath)\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def guided_backprop(input_model, images, layer_name):\n",
    "    \"\"\"Guided Backpropagation method for visualizing input saliency.\"\"\"\n",
    "    input_imgs = input_model.input\n",
    "    layer_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(layer_output, input_imgs)[0]\n",
    "    backprop_fn = K.function([input_imgs, K.learning_phase()], [grads])\n",
    "    grads_val = backprop_fn([images, 0])[0]\n",
    "    return grads_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u25T742fCF8Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def grad_cam(input_model, image, target_cls, layer_name):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.output[0, target_cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "    # Normalize if necessary\n",
    "    # grads = normalize(grads)\n",
    "    gradient_function = K.function([input_model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "    # Process CAM\n",
    "    cam = cv2.resize(cam, (H, W), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 of GradCAM the top changed imgs in [val set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make directories if not already exist\n",
    "categories = ['cat','dog','horse','person']\n",
    "imgLists = [img_cat, img_dog, img_horse, img_person]\n",
    "\n",
    "srcDir = './data/val/'\n",
    "targetDir = './CAMs/predchgs/'\n",
    "\n",
    "for f1 in ['GradCAM', 'G_GradCAM', 'G_BackProp']:\n",
    "  p1 = '{}{}/'.format(targetDir,f1)\n",
    "  if not os.path.exists(p1):\n",
    "    #print('{} path does not exist'.format(p1))\n",
    "    os.makedirs(p1)\n",
    "  for categ in categories:\n",
    "    p2='{}{}'.format(p1,categ)\n",
    "    if not os.path.exists(p2):\n",
    "      #print('{} path does not exist'.format(p2))\n",
    "      os.makedirs(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2008_004538.jpg' '2008_001531.jpg' '2008_001359.jpg' '2008_004538.jpg']\n",
      " ['2008_003374.jpg' '2008_004584.jpg' '2008_003975.jpg' '2008_001454.jpg']\n",
      " ['2008_002234.jpg' '2008_001789.jpg' '2008_005313.jpg' '2008_001205.jpg']]\n"
     ]
    }
   ],
   "source": [
    "print(topN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10, 633, 582,  10],\n",
       "       [179, 310, 194, 610],\n",
       "       [ 21, 721, 317, 533]], dtype=int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topNIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/val/cat/2008_004538.jpg exist\n",
      "./data/val/person/2008_001531.jpg exist\n",
      "./data/val/person/2008_001359.jpg exist\n",
      "./data/val/cat/2008_004538.jpg exist\n",
      "./data/val/dog/2008_003374.jpg exist\n",
      "./data/val/horse/2008_004584.jpg exist\n",
      "./data/val/dog/2008_003975.jpg exist\n",
      "./data/val/person/2008_001454.jpg exist\n",
      "./data/val/cat/2008_002234.jpg exist\n",
      "./data/val/person/2008_001789.jpg exist\n",
      "./data/val/horse/2008_005313.jpg exist\n",
      "./data/val/person/2008_001205.jpg exist\n"
     ]
    }
   ],
   "source": [
    "for imgList in topN:\n",
    "    for img in imgList:\n",
    "        for categ in categories:\n",
    "            p1 = '{}{}/{}'.format(srcDir,categ,img)\n",
    "            if not os.path.exists(p1):\n",
    "                continue\n",
    "            print('{} exist'.format(p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GENERATE CAMs FOR BASELINE MODEL\n",
    "layerName = 'block5_conv3'\n",
    "idx = 0\n",
    "chPruned = 0\n",
    "prunedLayer='base'\n",
    "prunedIdx='000'\n",
    "\n",
    "# NOTE: Project 'm2p01' is the right project for channel pruning\n",
    "baseModelPath  = './baseModel/modelBasev3.004-0.73.hdf5'\n",
    "baseModel = build_model(baseModelPath)\n",
    "guided_baseModel = build_guided_model(baseModelPath)\n",
    "\n",
    "#######################################################################\n",
    "for categ in categories:\n",
    "  for srcImgs in topN:\n",
    "    for srcImg in srcImgs:\n",
    "    \n",
    "      # Load npy img\n",
    "      imgPath = '{}{}/{}'.format(srcDir,categ,srcImg)\n",
    "      if not os.path.exists(imgPath):\n",
    "          continue\n",
    "#######################################################################\n",
    "      \n",
    "      img =load_image(imgPath)\n",
    "      pred_base = np.round(baseModel.predict(img)[0], decimals=2)\n",
    "      pred_base = np.array2string(pred_base,separator=',', formatter={'float_kind':lambda x: '{:.2f}'.format(x)})\n",
    "      pred_base = pred_base.replace('[','(').replace(']',')')\n",
    "  \n",
    "      # Perform {GradCAM, etc.} to explain all target_cls and save images\n",
    "      for target_cls in [0,1,2,3]:\n",
    "        p_or_t = 'b'\n",
    "        imgName = '{}_{}_{:03d}{}_{}_{}_{}_{}.jpg'.format(srcImg,target_cls,idx,p_or_t,prunedLayer, prunedIdx, chPruned, pred_base)\n",
    "        #imgName = '{}_{}_{:03d}{}_{}_{}.jpg'.format(srcImg,target_cls,idx,p_or_t,chPruned,pred_base)\n",
    "  \n",
    "        targetPath_gc  = '{}GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "        targetPath_ggc = '{}G_GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "        #targetPath_gb  = '{}G_BackProp/{}/{}'.format(targetDir,categ, imgName)\n",
    "  \n",
    "        gradcam = grad_cam(baseModel, img, target_cls, layerName)\n",
    "        gb = guided_backprop(guided_baseModel, img, layerName)\n",
    "        guided_gradcam = gb * gradcam[..., np.newaxis]\n",
    "  \n",
    "        jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
    "        jetcam = (np.float32(jetcam) + load_image(imgPath, preprocess=False)) / 2\n",
    "  \n",
    "        cv2.imwrite(targetPath_gc, np.uint8(jetcam))\n",
    "        #cv2.imwrite(targetPath_gb, deprocess_image(gb[0]))\n",
    "        cv2.imwrite(targetPath_ggc, deprocess_image(guided_gradcam[0]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYF1u684oeH9"
   },
   "source": [
    "## [val set] largest pred change: pruned-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FPtjtYN0ranx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/cmds.txt\", \"rb\") as fp:\n",
    "  cmds = pickle.load(fp)\n",
    "\n",
    "del pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cRSRGqWooeIA",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "contFromCmd = 0\n",
    "idx = contFromCmd*2+1\n",
    "#################################\n",
    "\n",
    "for i,cmd in enumerate(cmds[contFromCmd:], contFromCmd):\n",
    "  # Load prunedModel, tunedModel, guided_prunedModel, guided_tunedModel\n",
    "  # AND load chPruned, prunedLayer, prunedIdx\n",
    "  print('Loading models [cmd {}]'.format(i))\n",
    "  K.clear_session()\n",
    "  exec(cmd)\n",
    "  print('===')\n",
    "  \n",
    "  #######################################################################\n",
    "  for categ in categories:\n",
    "    for srcImgs in topN:\n",
    "      for srcImg in srcImgs:\n",
    "      \n",
    "      \n",
    "        # Load npy img\n",
    "        imgPath = '{}{}/{}'.format(srcDir,categ,srcImg)\n",
    "        if not os.path.exists(imgPath):\n",
    "            continue\n",
    "  #######################################################################\n",
    "      \n",
    "        # Load npy img\n",
    "        #imgPath = '{}{}/{}.jpg'.format(srcDir,categ,srcImg)\n",
    "        img =load_image(imgPath)\n",
    "        pred_pruned = np.round(prunedModel.predict(img)[0], decimals=2)\n",
    "        pred_pruned = np.array2string(pred_pruned,separator=',', formatter={'float_kind':lambda x: '{:.2f}'.format(x)})\n",
    "        pred_pruned = pred_pruned.replace('[','(').replace(']',')')\n",
    "        \n",
    "        pred_tuned  = np.round(tunedModel.predict(img)[0], decimals=2)\n",
    "        pred_tuned  = np.array2string(pred_tuned,separator=',', formatter={'float_kind':lambda x: '{:.2f}'.format(x)})\n",
    "        pred_tuned  = pred_tuned.replace('[','(').replace(']',')')\n",
    "        \n",
    "        # Perform GradCAM to explain all target_cls and save images\n",
    "        for target_cls in [0,1,2,3]:\n",
    "          p_or_t = 'p'\n",
    "          imgName = '{}_{}_{:03d}{}_{}_{}_{}_{}.jpg'.format(srcImg,target_cls,idx,p_or_t,prunedLayer, prunedIdx, chPruned,pred_pruned)\n",
    "          \n",
    "          targetPath_gc  = '{}GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "          targetPath_ggc = '{}G_GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "          #targetPath_gb  = '{}G_BackProp/{}/{}'.format(targetDir,categ, imgName)\n",
    "          \n",
    "          gradcam = grad_cam(prunedModel, img, target_cls, layerName)\n",
    "          gb = guided_backprop(guided_prunedModel, img, layerName)\n",
    "          guided_gradcam = gb * gradcam[..., np.newaxis]\n",
    "  \n",
    "          jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
    "          jetcam = (np.float32(jetcam) + load_image(imgPath, preprocess=False)) / 2\n",
    "  \n",
    "          cv2.imwrite(targetPath_gc, np.uint8(jetcam))\n",
    "          #cv2.imwrite(targetPath_gb, deprocess_image(gb[0]))\n",
    "          cv2.imwrite(targetPath_ggc, deprocess_image(guided_gradcam[0]))\n",
    "        print('{}: {}'.format(idx,imgName))\n",
    "        idx+=1\n",
    "        \n",
    "        for target_cls in [0,1,2,3]:\n",
    "          p_or_t = 't'\n",
    "          imgName = '{}_{}_{:03d}{}_{}_{}_{}_{}.jpg'.format(srcImg,target_cls,idx,p_or_t,prunedLayer, prunedIdx, chPruned,pred_tuned)\n",
    "  \n",
    "          targetPath_gc  = '{}GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "          targetPath_ggc = '{}G_GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "          #targetPath_gb  = '{}G_BackProp/{}/{}'.format(targetDir,categ, imgName)\n",
    "  \n",
    "          gradcam = grad_cam(tunedModel, img, target_cls, layerName)\n",
    "          gb = guided_backprop(guided_tunedModel, img, layerName)\n",
    "          guided_gradcam = gb * gradcam[..., np.newaxis]\n",
    "  \n",
    "          jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
    "          jetcam = (np.float32(jetcam) + load_image(imgPath, preprocess=False)) / 2\n",
    "  \n",
    "          cv2.imwrite(targetPath_gc, np.uint8(jetcam))\n",
    "          #cv2.imwrite(targetPath_gb, deprocess_image(gb[0]))\n",
    "          cv2.imwrite(targetPath_ggc, deprocess_image(guided_gradcam[0]))\n",
    "        print('{}: {}'.format(idx,imgName))\n",
    "        idx-=1\n",
    "  idx+=2"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "PruningProj2018 v1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:extractImgs_py3]",
   "language": "python",
   "name": "conda-env-extractImgs_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
