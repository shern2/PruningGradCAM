{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ForSharing_PruningProj2018.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rp9GMyU4Chrx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6KjZBNyVClow","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#!google-drive-ocamlfuse -cc\n","#!fusermount -u drive\n","#!mkdir -p drive\n","#!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"/content/drive/GPU/CS6208/\")\n","os.getcwd()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H4WIE9EeCusa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install -q keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hoUZrBWTEj6z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","from keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import VGG16\n","from keras.models import Model, load_model\n","from keras.layers import Dense, Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n","from keras.optimizers import Adam, SGD\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","import gc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Eh9DRBByKuvV","colab_type":"text"},"cell_type":"markdown","source":["## Base Model and Basic params"]},{"metadata":{"id":"IONCe3dJKuvX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["epochs = 200\n","batchSize = 64\n","trainSteps = 5798//batchSize +1\n","valSteps   =  783//batchSize +1\n","testSteps  =  354//batchSize +1\n","imgSize = 128\n","\n","\n","def ourModel(inputShape):\n","  \n","  num_classes = 4\n","\n","  base_model = VGG16(include_top=False,input_shape=inputShape)\n","  x = base_model.output\n","\n","  x = GlobalAveragePooling2D(name='glob_pool')(x)\n","  x = Dense(256, activation='relu', name='dense_1')(x)\n","  predictions = Dense(num_classes, activation='softmax', name='dense_F')(x)\n","\n","  model = Model(inputs=base_model.input, outputs=predictions)\n","  return model\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GM656Vm4Kuvb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Note that xTrain and xVal are normalized by /=255\n","xTrain = np.load('./data/xTrain.npy', mmap_mode='r')\n","yTrain = np.load('./data/yTrain.npy', mmap_mode='r')\n","xVal   = np.load('./data/xVal.npy', mmap_mode='r')\n","yVal   = np.load('./data/yVal.npy', mmap_mode='r')\n","\n","categories = ['cat','dog','horse','person']\n","datasets = ['train','val','test']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tI589EcVKuvj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model = ourModel((imgSize,imgSize,3))\n","opt = SGD(lr=0.001, momentum=0.9)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","earlyStop = EarlyStopping(monitor='val_loss', patience=2,verbose=1)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n","                                        factor=0.5,\n","                                        patience=0,\n","                                        verbose=1,\n","                                        epsilon=0.0001,\n","                                        cooldown=0,\n","                                        min_lr=0)\n","\n","\n","datagenTrain = ImageDataGenerator(featurewise_center=True,\n","    featurewise_std_normalization=True)\n","datagenTrain.fit(xTrain)\n","trainGen = datagenTrain.flow(xTrain,yTrain, batch_size=batchSize)\n","\n","datagenVal = ImageDataGenerator(featurewise_center=True,\n","    featurewise_std_normalization=True)\n","datagenVal.fit(xVal)\n","valGen = datagenVal.flow(xVal,yVal, batch_size=batchSize)\n","\n","# Checkpointer\n","dest_path = './baseModel/'\n","if not os.path.exists(dest_path):\n","  os.makedirs(dest_path)\n","    \n","filepath='{}modelBasev3.{{epoch:03d}}-{{val_loss:.2f}}.hdf5'.format(dest_path)\n","checkpointer = ModelCheckpoint(filepath, \n","                               #period=1,\n","                               save_weights_only=False, \n","                               monitor='val_loss', mode='auto',\n","                               save_best_only=True,\n","                               verbose=1)\n","\n","\n","model.fit_generator(trainGen, steps_per_epoch=trainSteps,\n","                    epochs=epochs,\n","                    validation_data=valGen, validation_steps=valSteps,\n","                    callbacks=[checkpointer, earlyStop, reduce_lr],\n","                    workers=1)\n","\n","# Score trained model\n","scores = model.evaluate(xVal, yVal, verbose=1)\n","print('Val loss:', scores[0])\n","print('Val accuracy:', scores[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"McHlKnftqm81","colab_type":"text"},"cell_type":"markdown","source":["## Prune and Tune\n","Tool: Keras Surgeon with corrected code\n","\n","(Source:https://github.com/BenWhetton/keras-surgeon; visited: 03/08/2018)"]},{"metadata":{"id":"RvEvzDExqm87","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Get conv and dense layer names (deepest layer first)\n","#for layer in reversed(model.layers):\n","#    print(layer.name)\n","\n","layerNames = ['dense_1',\n","              'block5_conv3','block5_conv2','block5_conv1',\n","              'block4_conv3','block4_conv2','block4_conv1',\n","              'block3_conv3','block3_conv2','block3_conv1',\n","              'block2_conv2','block2_conv1',\n","              'block1_conv2','block1_conv1']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"txI_YnOcqm84","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from kerassurgeon import identify\n","from kerassurgeon.operations import delete_channels\n","\n","#Initializations\n","#===============\n","# Initialize from last tuned layer\n","filepathLastTuned  = './baseModel/modelBasev3.004-0.73.hdf5'\n","model = load_model(filepathLastTuned, compile=False)\n","filepathTuned  = filepathLastTuned\n","\n","opt = SGD(lr=0.001, momentum=0.9)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","scores = model.evaluate(xVal, yVal, verbose=0)\n","print('Val loss:', scores[0])\n","print('Val accuracy:', scores[1])\n","baseAccuracy = scores[1]\n","\n","accThresh  = 0.03 # Pruning threshold (accuracy)\n","chThresh   = 20    # Pruning threshold (channel)\n","predAccuracy = baseAccuracy\n","bestAccuracy = baseAccuracy\n","batch_size = 64\n","num_classes = 4\n","epochs = 200\n","\n","earlyStop = EarlyStopping(monitor='val_loss', patience=2,verbose=1)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n","                                        factor=0.5,\n","                                        patience=0,\n","                                        verbose=1,\n","                                        epsilon=0.0001,\n","                                        cooldown=0,\n","                                        min_lr=0)\n","\n","datagenTrain = ImageDataGenerator()\n","datagenTrain.fit(xTrain)\n","trainGen = datagenTrain.flow(xTrain,yTrain, batch_size=batchSize)\n","\n","datagenVal = ImageDataGenerator()\n","datagenVal.fit(xVal)\n","valGen = datagenVal.flow(xVal,yVal, batch_size=batchSize)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dY-Fmedaqm9C","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["for layerName in layerNames:\n","  print('==========')\n","  print('Pruning {}\\'s channels'.format(layerName))\n","  \n","  currPrune = 0 # To include in name when saving pruned model\n","  \n","  dest_path = './models/m2p01_{}/'.format(layerName)\n","  if not os.path.exists(dest_path):\n","    os.makedirs(dest_path)\n","  \n","  # Reload the optimizer so that each layer starts with this lr\n","  opt = SGD(lr=0.001, momentum=0.9)\n","  \n","  while True:\n","\n","    # Prune channels\n","    layer = model.get_layer(name=layerName)\n","    apoz = identify.get_apoz(model, layer, valGen)\n","    high_apoz_channels = identify.high_apoz(apoz)\n","    if len(high_apoz_channels) < chThresh: \n","      print('Few channels left to prune: {} < chThresh {}'.format(len(high_apoz_channels), chThresh))\n","      break\n","    model = delete_channels(model, layer, high_apoz_channels, \n","                            copy=False)\n","\n","    model.compile(optimizer=opt,\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    \n","    #Manual rubbish collection\n","    gc.collect()\n","\n","    scores = model.evaluate(xVal, yVal,batch_size=batchSize,verbose=0)\n","    print('model after pruning: [loss,acc] = [{:.3f},{:.3f}]\\n'.format(scores[0],scores[1]))\n","\n","    # Save pruned model before tuning\n","    currPrune +=1\n","    filepathPruned=\"{}modelPruned.{}.{:03d}-{:03d}.hdf5\".format(dest_path,layerName,currPrune,len(high_apoz_channels))\n","    model.save(filepathPruned,include_optimizer=False)\n","\n","    # Save pruned channel indices\n","    filepathPruned_idx = \"{}modelPruned.{}.{:03d}-{:03d}_ch.npy\".format(dest_path,layerName,currPrune,len(high_apoz_channels))\n","    np.save(filepathPruned_idx, high_apoz_channels)\n","\n","    # Save predictions (pre-tune)\n","    pred = model.predict(xVal, batch_size=batchSize)\n","    filepathPruned_pred = \"{}modelPruned.{}.{:03d}-{:03d}_pred.npy\".format(dest_path,layerName,currPrune,len(high_apoz_channels))\n","    np.save(filepathPruned_pred, pred)\n","\n","    \n","    model.fit_generator(trainGen, steps_per_epoch=trainSteps,\n","                    epochs=epochs,\n","                    validation_data=valGen, validation_steps=valSteps,\n","                    callbacks=[earlyStop, reduce_lr],\n","                    verbose = 1,\n","                    workers=1)\n","    \n","    scores = model.evaluate(xVal, yVal,batch_size=batchSize,verbose=0)\n","    print('model after retraining: [loss,acc] = [{:.3f},{:.3f}]\\n'.format(scores[0],scores[1]))\n","    \n","\n","    # Save tuned model after earlyStop\n","    filepathTuned      = \"{}modelTuned.{}.{:03d}-{:03d}.hdf5\".format(dest_path,layerName,currPrune,len(high_apoz_channels))\n","    model.save(filepathTuned,include_optimizer=False)\n","\n","    # Save predictions (tuned)\n","    pred = model.predict(xVal, batch_size=batchSize)\n","    filepathTuned_pred = \"{}modelTuned.{}.{:03d}-{:03d}_pred.npy\".format(dest_path,layerName,currPrune,len(high_apoz_channels))\n","    np.save(filepathTuned_pred, pred)\n","\n","    # Exit while-loop if predAccuracy performs worse than some threshold\n","    _, predAccuracy = model.evaluate(xVal, yVal,batch_size=batchSize,verbose=0)\n","    if predAccuracy > bestAccuracy:\n","      bestAccuracy = predAccuracy\n","    elif (bestAccuracy-predAccuracy) > accThresh:\n","      print('Accuracy fell too much: {:.3f} > accThresh {:.3f}'.format((bestAccuracy-predAccuracy), accThresh))\n","      break\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"egBzZoOhossc","colab_type":"text"},"cell_type":"markdown","source":["**(continue where last left-off) (if applicable)**\n","\n","Stopped after block2_conv1 (block1_conv2, block1_conv1 not pruned) Likely due to insufficient memory (I believe Keras Surgeon implementation has to build a graph on depedent nodes)"]}]}