{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9272,
     "status": "ok",
     "timestamp": 1524002422978,
     "user": {
      "displayName": "Shern Yap",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100597149862734635322"
     },
     "user_tz": -480
    },
    "id": "hoUZrBWTEj6z",
    "outputId": "bc36a870-2494-4747-a308-742d2ad2be81"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPC0qvrMCd2t"
   },
   "source": [
    "## GradCAM\n",
    "Credits: https://github.com/eclique/keras-gradcam; Last Visited: 23/02/2018\n",
    "Modified implementation (e.g. decode_predictions(), build_model(), load_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-p23gNSnCF8B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from imageio import imread, mimsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "36r1iwiICF8I"
   },
   "outputs": [],
   "source": [
    "imgSize=128\n",
    "H = imgSize\n",
    "W = imgSize\n",
    "\n",
    "N_CLASS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYrAIRdnCF8K"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vSQSOcFEQ6t0"
   },
   "outputs": [],
   "source": [
    "def build_model(modelPath):\n",
    "  \"\"\"Function returning keras model instance.\n",
    "  \"\"\"\n",
    "  model = load_model(modelPath, compile=False)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_W6hjArKCF8L"
   },
   "outputs": [],
   "source": [
    "def load_image(path, preprocess=True):\n",
    "  \"\"\"Load and preprocess image.\"\"\"\n",
    "  if preprocess:\n",
    "    x = np.array(imread(path),dtype=np.float32)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "    x/=255. # This was the only preprocessing I did... rather than keras.applications.preprocess_input(x)\n",
    "  else:\n",
    "    x = image.load_img(path, target_size=(H, W))\n",
    "  return x\n",
    "#def load_image(path, preprocess=True):\n",
    "#  \"\"\"Load and preprocess image.\"\"\"\n",
    "#  x = image.load_img(path, target_size=(H, W))\n",
    "#  if preprocess:\n",
    "#      x = image.img_to_array(x)\n",
    "#      x = np.expand_dims(x, axis=0)\n",
    "#      x = preprocess_input(x)\n",
    "#  return x\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "  \"\"\"Same normalization as in:\n",
    "  https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "  \"\"\"\n",
    "  x = x.copy()\n",
    "  if np.ndim(x) > 3:\n",
    "    x = np.squeeze(x)\n",
    "  # normalize tensor: center on 0., ensure std is 0.1\n",
    "  x -= x.mean()\n",
    "  x /= (x.std() + 1e-5)\n",
    "  x *= 0.1\n",
    "\n",
    "  # clip to [0, 1]\n",
    "  x += 0.5\n",
    "  x = np.clip(x, 0, 1)\n",
    "\n",
    "  # convert to RGB array\n",
    "  x *= 255\n",
    "  if K.image_dim_ordering() == 'th':\n",
    "    x = x.transpose((1, 2, 0))\n",
    "  x = np.clip(x, 0, 255).astype('uint8')\n",
    "  return x\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "  \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "  return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NohZZJ4yIESE"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "\n",
    "CLASS_INDEX = json.load(open('./myModel_class_index.json'))\n",
    "    \n",
    "def decode_predictions(preds, top=4):\n",
    "    \"\"\"Decodes the prediction of ourModel.\n",
    "    # Arguments\n",
    "        preds: Numpy tensor encoding a batch of predictions.\n",
    "        top: Integer, how many top-guesses to return.\n",
    "    # Returns\n",
    "        A list of lists of top class prediction tuples\n",
    "        `(class_name, class_description, score)`.\n",
    "        One list of tuples per sample in batch input.\n",
    "    # Raises\n",
    "        ValueError: In case of invalid shape of the `pred` array\n",
    "            (must be 2D).\n",
    "    # Note: this is a modification of keras.applications.imagenet_utils.preprocess_input\n",
    "    \"\"\"\n",
    "    global CLASS_INDEX\n",
    "    if len(preds.shape) != 2 or preds.shape[1] != 4:\n",
    "        raise ValueError('`decode_predictions` expects '\n",
    "                         'a batch of predictions '\n",
    "                         '(i.e. a 2D array of shape (samples, 4)). '\n",
    "                         'Found array with shape: ' + str(preds.shape))\n",
    "    \n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
    "        result.sort(key=lambda x: x[2], reverse=True)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdVwJ0KNCF8N"
   },
   "source": [
    "### Guided Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WCMGommvCF8O"
   },
   "outputs": [],
   "source": [
    "def build_guided_model(modelPath):\n",
    "    \"\"\"Function returning modified model.\n",
    "    \n",
    "    Changes gradient function for all ReLu activations\n",
    "    according to Guided Backpropagation.\n",
    "    \"\"\"\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) * \\\n",
    "                   tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': 'GuidedBackProp'}):\n",
    "        new_model = build_model(modelPath)\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def guided_backprop(input_model, images, layer_name):\n",
    "    \"\"\"Guided Backpropagation method for visualizing input saliency.\"\"\"\n",
    "    input_imgs = input_model.input\n",
    "    layer_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(layer_output, input_imgs)[0]\n",
    "    backprop_fn = K.function([input_imgs, K.learning_phase()], [grads])\n",
    "    grads_val = backprop_fn([images, 0])[0]\n",
    "    return grads_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLsFguH4CF8Q"
   },
   "source": [
    "### GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u25T742fCF8Q"
   },
   "outputs": [],
   "source": [
    "def grad_cam(input_model, image, target_cls, layer_name):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.output[0, target_cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "    # Normalize if necessary\n",
    "    # grads = normalize(grads)\n",
    "    gradient_function = K.function([input_model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "    # Process CAM\n",
    "    cam = cv2.resize(cam, (H, W), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hR-xcyV5gitp"
   },
   "source": [
    "# Generate GradCAM across pruning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6gKjOVWNgneJ"
   },
   "outputs": [],
   "source": [
    "# Generate commands for the 91 models: {baseModel, 45 x prunedModel, 45 x tunedModel}\n",
    "# Analyze 3 imgs per class (from test set only). Total 12 imgs (since 4 classes)\n",
    "# For each img, {GradCAM, GuidedBackprop, GuidedGradCAM} per class. Total 12 CAMs (since 4 classes)\n",
    "\n",
    "\n",
    "# Selected imgs this way: \n",
    "# 1 img that is obviously the target class, the other 2 imgs that are ambiguous (e.g. multiple classes per img or potentially misleading)\n",
    "img_cat    = ['2008_000536', '2008_000950', '2008_000660']\n",
    "img_dog    = ['2008_000162', '2008_000829', '2008_001436']\n",
    "img_horse  = ['2008_000141', '2008_000552', '2008_000880']\n",
    "img_person = ['2008_000436', '2008_000316', '2008_000277']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQdRL-8XFoDv"
   },
   "source": [
    "## Setup and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17951,
     "status": "ok",
     "timestamp": 1524013315372,
     "user": {
      "displayName": "Shern Yap",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100597149862734635322"
     },
     "user_tz": -480
    },
    "id": "gYANC2Kd1GkC",
    "outputId": "84807ec9-c082-4183-8f67-6f3d36cde901"
   },
   "outputs": [],
   "source": [
    "# Make directories if not already exist\n",
    "categories = ['cat','dog','horse','person']\n",
    "targetDir = './CAMs/'\n",
    "\n",
    "for f1 in ['GradCAM', 'G_GradCAM', 'G_BackProp']:\n",
    "  p1 = '{}{}/'.format(targetDir,f1)\n",
    "  if not os.path.exists(p1):\n",
    "    #print('{} path does not exist'.format(p1))\n",
    "    os.makedirs(p1)\n",
    "  for categ in categories:\n",
    "    p2='{}{}'.format(p1,categ)\n",
    "    if not os.path.exists(p2):\n",
    "      #print('{} path does not exist'.format(p2))\n",
    "      os.makedirs(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QqGhDffbuFs9"
   },
   "outputs": [],
   "source": [
    "# GENERATE CAMs FOR BASELINE MODEL\n",
    "categories = ['cat','dog','horse','person']\n",
    "imgLists = [img_cat, img_dog, img_horse, img_person]\n",
    "\n",
    "srcDir = './data/test/'\n",
    "targetDir = './CAMs/'\n",
    "\n",
    "layerName = 'block5_conv3'\n",
    "idx = 0\n",
    "chPruned = 0\n",
    "prunedLayer='base'\n",
    "prunedIdx='000'\n",
    "\n",
    "# NOTE: Project 'm2p01' is the right project for channel pruning\n",
    "baseModelPath  = './baseModel/modelBasev3.004-0.73.hdf5'\n",
    "baseModel = build_model(baseModelPath)\n",
    "guided_baseModel = build_guided_model(baseModelPath)\n",
    "\n",
    "for categ, imgList in zip(categories, imgLists):\n",
    "  for srcImg in imgList:\n",
    "    # Load npy img\n",
    "    imgPath = '{}{}/{}.jpg'.format(srcDir,categ,srcImg)\n",
    "    img =load_image(imgPath)\n",
    "    pred_base = np.round(baseModel.predict(img)[0], decimals=2)\n",
    "    pred_base = np.array2string(pred_base,separator=',', formatter={'float_kind':lambda x: '{:.2f}'.format(x)})\n",
    "    pred_base = pred_base.replace('[','(').replace(']',')')\n",
    "\n",
    "    # Perform {GradCAM, etc.} to explain all target_cls and save images\n",
    "    for target_cls in [0,1,2,3]:\n",
    "      p_or_t = 'b'\n",
    "      imgName = '{}_{}_{:03d}{}_{}_{}_{}_{}.jpg'.format(srcImg,target_cls,idx,p_or_t,prunedLayer, prunedIdx, chPruned, pred_base)\n",
    "\n",
    "      targetPath_gc  = '{}GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "      targetPath_ggc = '{}G_GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "      #targetPath_gb  = '{}G_BackProp/{}/{}'.format(targetDir,categ, imgName)\n",
    "\n",
    "      gradcam = grad_cam(baseModel, img, target_cls, layerName)\n",
    "      gb = guided_backprop(guided_baseModel, img, layerName)\n",
    "      guided_gradcam = gb * gradcam[..., np.newaxis]\n",
    "\n",
    "      jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
    "      jetcam = (np.float32(jetcam) + load_image(imgPath, preprocess=False)) / 2\n",
    "\n",
    "      cv2.imwrite(targetPath_gc, np.uint8(jetcam))\n",
    "      #cv2.imwrite(targetPath_gb, deprocess_image(gb[0]))\n",
    "      cv2.imwrite(targetPath_ggc, deprocess_image(guided_gradcam[0]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNgAm6_IFxHl"
   },
   "source": [
    "## cmds to build model & guided_model (run once only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xPqdOME8v5PV"
   },
   "outputs": [],
   "source": [
    "# Generate cmds to build the model & guided_model()\n",
    "#===============================\n",
    "cmds =[]\n",
    "proj = 'm2p01_' #project name\n",
    "folderList = [s for s in os.listdir('./models/') if s.startswith(proj)]\n",
    "\n",
    "for f in folderList:\n",
    "  files = os.listdir('./models/{}/'.format(f))\n",
    "  # Ignore empty folders\n",
    "  if len(files)==0: continue\n",
    "  \n",
    "  for file in files:\n",
    "    \n",
    "    # Extract info\n",
    "    chPruned = file.split('.')[2]\n",
    "    prunedIdx = chPruned[:3]\n",
    "    chPruned = chPruned[-3:]\n",
    "    prunedLayer = file.split('.')[1]\n",
    "    \n",
    "    if (file.startswith('modelPruned') & file.endswith('.hdf5')):      \n",
    "      modelName = 'prunedModel'\n",
    "      cmd1 = 'chPruned = \\'{}\\'; prunedLayer = \\'{}\\'; prunedIdx = \\'{}\\''.format(chPruned, prunedLayer,prunedIdx)\n",
    "      cmd2 = '{} = build_model(\\'./models/{}/{}\\')'.format(modelName,f,file)\n",
    "      cmd3 = 'guided_{} = build_guided_model(\\'./models/{}/{}\\')'.format(modelName,f,file)\n",
    "      cmds.append(\"\\n\".join([cmd1,cmd2,cmd3]))\n",
    "    elif (file.startswith('modelTuned') & file.endswith('.hdf5')):\n",
    "      modelName = 'tunedModel'\n",
    "      cmd2 = '{} = build_model(\\'./models/{}/{}\\')'.format(modelName,f,file)\n",
    "      cmd3 = 'guided_{} = build_guided_model(\\'./models/{}/{}\\')'.format(modelName,f,file)\n",
    "      cmds.append(\"\\n\".join([cmd2,cmd3]))\n",
    "      \n",
    "# Combine the cmds for each pruned-tuned together\n",
    "cmds_v2=[]\n",
    "for i in range(0,len(cmds),2):\n",
    "  cmds_v2.append(\"\\n\".join([cmds[i],cmds[i+1]]))\n",
    "cmds = cmds_v2  \n",
    "  \n",
    "  \n",
    "del files, cmds_v2, folderList, chPruned, prunedIdx, prunedLayer, modelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "VmPCNv9msDQX"
   },
   "outputs": [],
   "source": [
    "#Save cmds\n",
    "import pickle\n",
    "with open(\"./data/cmds.txt\", \"wb\") as fp:\n",
    "  pickle.dump(cmds, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYF1u684oeH9"
   },
   "source": [
    "## pruned-tuned (cmd 0 to cmd 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GvIyPkk6olxx"
   },
   "outputs": [],
   "source": [
    "# RELOAD BASELINE\n",
    "categories = ['cat','dog','horse','person']\n",
    "imgLists = [img_cat, img_dog, img_horse, img_person]\n",
    "\n",
    "srcDir = './data/test/'\n",
    "targetDir = './CAMs/'\n",
    "\n",
    "layerName = 'block5_conv3'\n",
    "idx = 0\n",
    "chPruned = 0\n",
    "\n",
    "# NOTE: Project 'm2p01' is the right project for channel pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FPtjtYN0ranx"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/cmds.txt\", \"rb\") as fp:\n",
    "  cmds = pickle.load(fp)\n",
    "\n",
    "del pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cRSRGqWooeIA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CONTINUE FROM CMD0, idx 1\n",
    "# ==================\n",
    "categories = ['cat','dog','horse','person']\n",
    "imgLists = [img_cat, img_dog, img_horse, img_person]\n",
    "\n",
    "srcDir = './data/test/'\n",
    "targetDir = './CAMs/'\n",
    "\n",
    "layerName = 'block5_conv3'\n",
    "#################################\n",
    "contFromCmd = 0\n",
    "idx = contFromCmd*2+1\n",
    "#################################\n",
    "\n",
    "for i,cmd in enumerate(cmds[contFromCmd:], contFromCmd):\n",
    "  # Load prunedModel, tunedModel, guided_prunedModel, guided_tunedModel\n",
    "  # AND load chPruned, prunedLayer, prunedIdx\n",
    "  print('Loading models [cmd {}]'.format(i))\n",
    "  K.clear_session()\n",
    "  exec(cmd)\n",
    "  print('===')\n",
    "  \n",
    "  for categ, imgList in zip(categories, imgLists):\n",
    "    for srcImg in imgList:\n",
    "      \n",
    "      # Load npy img\n",
    "      imgPath = '{}{}/{}.jpg'.format(srcDir,categ,srcImg)\n",
    "      img =load_image(imgPath)\n",
    "      pred_pruned = np.round(prunedModel.predict(img)[0], decimals=2)\n",
    "      pred_pruned = np.array2string(pred_pruned,separator=',', formatter={'float_kind':lambda x: '{:.2f}'.format(x)})\n",
    "      pred_pruned = pred_pruned.replace('[','(').replace(']',')')\n",
    "      \n",
    "      pred_tuned  = np.round(tunedModel.predict(img)[0], decimals=2)\n",
    "      pred_tuned  = np.array2string(pred_tuned,separator=',', formatter={'float_kind':lambda x: '{:.2f}'.format(x)})\n",
    "      pred_tuned  = pred_tuned.replace('[','(').replace(']',')')\n",
    "      \n",
    "      # Perform GradCAM to explain all target_cls and save images\n",
    "      for target_cls in [0,1,2,3]:\n",
    "        p_or_t = 'p'\n",
    "        imgName = '{}_{}_{:03d}{}_{}_{}_{}_{}.jpg'.format(srcImg,target_cls,idx,p_or_t,prunedLayer, prunedIdx, chPruned,pred_pruned)\n",
    "        \n",
    "        targetPath_gc  = '{}GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "        targetPath_ggc = '{}G_GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "        #targetPath_gb  = '{}G_BackProp/{}/{}'.format(targetDir,categ, imgName)\n",
    "        \n",
    "        gradcam = grad_cam(prunedModel, img, target_cls, layerName)\n",
    "        gb = guided_backprop(guided_prunedModel, img, layerName)\n",
    "        guided_gradcam = gb * gradcam[..., np.newaxis]\n",
    "\n",
    "        jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
    "        jetcam = (np.float32(jetcam) + load_image(imgPath, preprocess=False)) / 2\n",
    "\n",
    "        cv2.imwrite(targetPath_gc, np.uint8(jetcam))\n",
    "        #cv2.imwrite(targetPath_gb, deprocess_image(gb[0]))\n",
    "        cv2.imwrite(targetPath_ggc, deprocess_image(guided_gradcam[0]))\n",
    "      print('{}: {}'.format(idx,imgName))\n",
    "      idx+=1\n",
    "      \n",
    "      for target_cls in [0,1,2,3]:\n",
    "        p_or_t = 't'\n",
    "        imgName = '{}_{}_{:03d}{}_{}_{}_{}_{}.jpg'.format(srcImg,target_cls,idx,p_or_t,prunedLayer, prunedIdx, chPruned,pred_tuned)\n",
    "\n",
    "        targetPath_gc  = '{}GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "        targetPath_ggc = '{}G_GradCAM/{}/{}'.format(targetDir,categ, imgName)\n",
    "        #targetPath_gb  = '{}G_BackProp/{}/{}'.format(targetDir,categ, imgName)\n",
    "\n",
    "        gradcam = grad_cam(tunedModel, img, target_cls, layerName)\n",
    "        gb = guided_backprop(guided_tunedModel, img, layerName)\n",
    "        guided_gradcam = gb * gradcam[..., np.newaxis]\n",
    "\n",
    "        jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
    "        jetcam = (np.float32(jetcam) + load_image(imgPath, preprocess=False)) / 2\n",
    "\n",
    "        cv2.imwrite(targetPath_gc, np.uint8(jetcam))\n",
    "        #cv2.imwrite(targetPath_gb, deprocess_image(gb[0]))\n",
    "        cv2.imwrite(targetPath_ggc, deprocess_image(guided_gradcam[0]))\n",
    "      print('{}: {}'.format(idx,imgName))\n",
    "      idx-=1\n",
    "  idx+=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(filenames, duration, savePath):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(imread(filename))\n",
    "    #output_file = 'Gif-%s.gif' % datetime.datetime.now().strftime('%Y-%M-%d-%H-%M-%S')\n",
    "    #imageio.mimsave(output_file, images, duration=duration)\n",
    "    mimsave(savePath, images, duration=duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories if not already exist\n",
    "categories = ['cat','dog','horse','person']\n",
    "targetDir = './CAMs/'\n",
    "\n",
    "for f1 in ['GradCAM_idx', 'G_GradCAM_idx', 'G_BackProp_idx']:\n",
    "  p1 = '{}{}/'.format(targetDir,f1)\n",
    "  if not os.path.exists(p1):\n",
    "    #print('{} path does not exist'.format(p1))\n",
    "    os.makedirs(p1)\n",
    "  for categ in categories:\n",
    "    p2='{}{}'.format(p1,categ)\n",
    "    if not os.path.exists(p2):\n",
    "      #print('{} path does not exist'.format(p2))\n",
    "      os.makedirs(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ANNOTATING Images (for GIF creation later)\n",
    "categories = ['cat','dog','horse','person']\n",
    "\n",
    "srcDir    = './CAMs/'\n",
    "\n",
    "for f1 in ['GradCAM', 'G_GradCAM']:\n",
    "  for categ in categories:\n",
    "    imgPath = '{}{}/{}/'.format(srcDir, f1, categ)\n",
    "    files = ['{}{}'.format(imgPath, s) for s in os.listdir(imgPath)]\n",
    "    \n",
    "    for file in files:\n",
    "      #Note cv2 uses BGR instead of RGB >> To be consistent use cv2 to read and write\n",
    "      img = cv2.imread(file)\n",
    "      splitFile = file.split('/')\n",
    "      targetPath = './{}/{}_idx/{}/{}'.format(splitFile[1],splitFile[2],splitFile[3],splitFile[4])\n",
    "      idx = splitFile[4][15:17]\n",
    "      if len(idx) ==1: idx=' '+idx\n",
    "      img = cv2.putText(img, idx, (115, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1, cv2.LINE_8)\n",
    "      cv2.imwrite(targetPath, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR GRADCAM pruned-tuned GIFs (base->pruned->tuned->pruned->tuned->...)\n",
    "categories = ['cat','dog','horse','person']\n",
    "imgLists =[img_cat, img_dog, img_horse, img_person]\n",
    "\n",
    "srcDir    = './CAMs/GradCAM_idx/'\n",
    "targetDir = './CAMs/GradCAM_idx/prune-tune GIFs/'\n",
    "\n",
    "for categ, imgList in zip(categories, imgLists):\n",
    "  for target_cls in [0,1,2,3]:\n",
    "    for srcImg in imgList:\n",
    "      imgPath = '{}{}/'.format(srcDir,categ)\n",
    "      files = ['{}{}'.format(imgPath, s) for s in os.listdir(imgPath) if s.startswith('{}_{}'.format(srcImg,target_cls))]\n",
    "      \n",
    "      splitFile = files[0].split('/')\n",
    "      targetPath = '{}{}_{}_{}to{}.gif'.format(targetDir,srcImg, target_cls,\n",
    "                                                 files[0].split('/')[4][:-4][-21:],files[-1].split('/')[4][:-4][-21:])\n",
    "  \n",
    "      gifDuration = [0.4 for _ in range(len(files))]\n",
    "      gifDuration[0] = 3\n",
    "      gifDuration[-1]= 3\n",
    "      create_gif(files,gifDuration,targetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR GRADCAM tuned GIFs (base->tuned->tuned->...)\n",
    "categories = ['cat','dog','horse','person']\n",
    "imgLists =[img_cat, img_dog, img_horse, img_person]\n",
    "\n",
    "srcDir    = './CAMs/GradCAM_idx/'\n",
    "targetDir = './CAMs/GradCAM_idx/tune GIFs/'\n",
    "\n",
    "for categ, imgList in zip(categories, imgLists):\n",
    "  for target_cls in [0,1,2,3]:\n",
    "    for srcImg in imgList:\n",
    "      imgPath = '{}{}/'.format(srcDir,categ)\n",
    "      files = ['{}{}'.format(imgPath, s) for s in os.listdir(imgPath) if s.startswith('{}_{}'.format(srcImg,target_cls)) & (s[17]!='p')]\n",
    "      splitFile = files[0].split('/')\n",
    "      targetPath = '{}{}_{}_{}to{}.gif'.format(targetDir,srcImg, target_cls,\n",
    "                                                 files[0].split('/')[4][:-4][-21:],files[-1].split('/')[4][:-4][-21:])\n",
    "  \n",
    "      gifDuration = [0.4 for _ in range(len(files))]\n",
    "      gifDuration[0] = 3\n",
    "      gifDuration[-1]= 3\n",
    "      create_gif(files,gifDuration,targetPath)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR Guided-GRADCAM pruned-tuned GIFs (base->pruned->tuned->pruned->tuned->...)\n",
    "categories = ['cat','dog','horse','person']\n",
    "imgLists =[img_cat, img_dog, img_horse, img_person]\n",
    "\n",
    "srcDir    = './CAMs/G_GradCAM_idx/'\n",
    "targetDir = './CAMs/G_GradCAM_idx/prune-tune GIFs/'\n",
    "\n",
    "for categ, imgList in zip(categories, imgLists):\n",
    "  for target_cls in [0,1,2,3]:\n",
    "    for srcImg in imgList:\n",
    "      imgPath = '{}{}/'.format(srcDir,categ)\n",
    "      files = ['{}{}'.format(imgPath, s) for s in os.listdir(imgPath) if s.startswith('{}_{}'.format(srcImg,target_cls))]\n",
    "      \n",
    "      splitFile = files[0].split('/')\n",
    "      targetPath = '{}{}_{}_{}to{}.gif'.format(targetDir,srcImg, target_cls,\n",
    "                                                 files[0].split('/')[4][:-4][-21:],files[-1].split('/')[4][:-4][-21:])\n",
    "  \n",
    "      gifDuration = [0.4 for _ in range(len(files))]\n",
    "      gifDuration[0] = 3\n",
    "      gifDuration[-1]= 3\n",
    "      create_gif(files,gifDuration,targetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR Guided-GRADCAM tuned GIFs (base->tuned->tuned->...)\n",
    "categories = ['cat','dog','horse','person']\n",
    "imgLists =[img_cat, img_dog, img_horse, img_person]\n",
    "\n",
    "srcDir    = './CAMs/G_GradCAM_idx/'\n",
    "targetDir = './CAMs/G_GradCAM_idx/tune GIFs/'\n",
    "\n",
    "for categ, imgList in zip(categories, imgLists):\n",
    "  for target_cls in [0,1,2,3]:\n",
    "    for srcImg in imgList:\n",
    "      imgPath = '{}{}/'.format(srcDir,categ)\n",
    "      files = ['{}{}'.format(imgPath, s) for s in os.listdir(imgPath) if s.startswith('{}_{}'.format(srcImg,target_cls)) & (s[17]!='p')]\n",
    "      splitFile = files[0].split('/')\n",
    "      targetPath = '{}{}_{}_{}to{}.gif'.format(targetDir,srcImg, target_cls,\n",
    "                                                 files[0].split('/')[4][:-4][-21:],files[-1].split('/')[4][:-4][-21:])\n",
    "  \n",
    "      gifDuration = [0.4 for _ in range(len(files))]\n",
    "      gifDuration[0] = 3\n",
    "      gifDuration[-1]= 3\n",
    "      create_gif(files,gifDuration,targetPath)      \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "PruningProj2018 v1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:extractImgs_py3]",
   "language": "python",
   "name": "conda-env-extractImgs_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
